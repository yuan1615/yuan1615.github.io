<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">
<link href="https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css" rel="stylesheet">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yuan1615.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="æ‘˜è¦ G2PWï¼šA ConditionalWeighted Softmax BERT for Polyphone Disambiguation in Mandarin è®ºæ–‡æœ€äº®ç‚¹çš„åœ°æ–¹æ˜¯å…¬å¼€äº†åŸºäº Mandarin Polyphone dataset with Bopomofo (MPB) æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹å‚æ•°ğŸ‘ï¼ŒMPBæ•°æ®é›†å…±åŒ…å«436ä¸ªå¤šéŸ³å­—ï¼Œ2610344æ¡åŒ…å«å¤šéŸ³å­—çš„æ–‡æœ¬ã€‚  è®ºæ–‡åœ°å€">
<meta property="og:type" content="article">
<meta property="og:title" content="G2PW">
<meta property="og:url" content="https://yuan1615.github.io/2022/08/08/G2PW/index.html">
<meta property="og:site_name" content="1615">
<meta property="og:description" content="æ‘˜è¦ G2PWï¼šA ConditionalWeighted Softmax BERT for Polyphone Disambiguation in Mandarin è®ºæ–‡æœ€äº®ç‚¹çš„åœ°æ–¹æ˜¯å…¬å¼€äº†åŸºäº Mandarin Polyphone dataset with Bopomofo (MPB) æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹å‚æ•°ğŸ‘ï¼ŒMPBæ•°æ®é›†å…±åŒ…å«436ä¸ªå¤šéŸ³å­—ï¼Œ2610344æ¡åŒ…å«å¤šéŸ³å­—çš„æ–‡æœ¬ã€‚  è®ºæ–‡åœ°å€">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://yuan1615.github.io/2022/08/08/G2PW/g2pw.jpg">
<meta property="og:image" content="https://yuan1615.github.io/2022/08/08/G2PW/cond-weight.jpg">
<meta property="article:published_time" content="2022-08-08T06:19:59.000Z">
<meta property="article:modified_time" content="2022-08-10T08:26:49.537Z">
<meta property="article:author" content="Xin Yuan">
<meta property="article:tag" content="TTS Front-end">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yuan1615.github.io/2022/08/08/G2PW/g2pw.jpg">

<link rel="canonical" href="https://yuan1615.github.io/2022/08/08/G2PW/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>G2PW | 1615</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">1615</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://yuan1615.github.io/2022/08/08/G2PW/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/me.jpg">
      <meta itemprop="name" content="Xin Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="1615">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          G2PW
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-08-08 14:19:59" itemprop="dateCreated datePublished" datetime="2022-08-08T14:19:59+08:00">2022-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-08-10 16:26:49" itemprop="dateModified" datetime="2022-08-10T16:26:49+08:00">2022-08-10</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Text-to-Speech/" itemprop="url" rel="index"><span itemprop="name">Text to Speech</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="æ‘˜è¦"><a class="markdownIt-Anchor" href="#æ‘˜è¦"></a> æ‘˜è¦</h1>
<p><strong>G2PW</strong>ï¼šA ConditionalWeighted Softmax BERT for Polyphone Disambiguation in Mandarin</p>
<p>è®ºæ–‡æœ€äº®ç‚¹çš„åœ°æ–¹æ˜¯å…¬å¼€äº†åŸºäº Mandarin Polyphone dataset with Bopomofo (MPB) æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹å‚æ•°ğŸ‘ï¼ŒMPBæ•°æ®é›†å…±åŒ…å«436ä¸ªå¤šéŸ³å­—ï¼Œ2610344æ¡åŒ…å«å¤šéŸ³å­—çš„æ–‡æœ¬ã€‚</p>
<ul>
<li>è®ºæ–‡åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2203.10430.pdf">https://arxiv.org/pdf/2203.10430.pdf</a></li>
<li>ä»£ç åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://github.com/GitYCC/g2pW">https://github.com/GitYCC/g2pW</a></li>
<li>åŸºäºMPBè®­ç»ƒçš„æ¨¡å‹åœ°å€ï¼š<a target="_blank" rel="noopener" href="https://storage.googleapis.com/esun-ai/g2pW/G2PWModel-v1.zip">https://storage.googleapis.com/esun-ai/g2pW/G2PWModel-v1.zip</a></li>
</ul>
<span id="more"></span>
<h2 id="ä¸»è¦æ¡†æ¶"><a class="markdownIt-Anchor" href="#ä¸»è¦æ¡†æ¶"></a> ä¸»è¦æ¡†æ¶</h2>
<p>æ¨¡å‹æ•´ä½“æ¡†æ¶å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="/2022/08/08/G2PW/g2pw.jpg" alt="g2pw"></p>
<p>conditional weight layeræ¡†æ¶å¦‚ä¸‹å›¾ï¼š</p>
<p><img src="/2022/08/08/G2PW/cond-weight.jpg" alt="cond-weight"></p>
<p>ä¸»è¦é—®é¢˜å¦‚ä¸‹ï¼š</p>
<ul>
<li>æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ä¸­çš„ <code>POLYPHONIC_CHARS.txt</code> å­—å…¸å­˜åœ¨ä¸è¶³ï¼Œä¼šå­˜åœ¨æŸäº›å¸¸è§å¤šéŸ³å­—ä¸åœ¨å¤šéŸ³å­—å­—å…¸çš„ç°è±¡ï¼Œæ–‡æœ«æä¾›äº†æ”¹å–„æ–¹æ³•</li>
<li>æœ€å¤§çš„ç—›ç‚¹æ˜¯æ¨æ–­æ…¢ï¼Œè¿™ä¸ªæ˜¯æ¨¡å‹æœ¬èº«è®¾è®¡å¯¼è‡´çš„ï¼Œéœ€è¦ä¿®æ”¹æ¡†æ¶ï¼Œæ”¹äº†æ¡†æ¶æˆ‘å°±æ²¡æœ‰è¿™ä¹ˆå¤šæ•°æ®å»è®­ç»ƒäº†ğŸ¤£ã€‚æ¨æ–­æ…¢çš„åŸå› æ˜¯æ¯ä¸ªå¥å­ä¼šå‡ºç°å¾ˆå¤šå¤šéŸ³å­—ï¼Œå¦‚<code>æ¬¢è¿æ‹¨æ‰“å«å¥å§”æµè°ƒç”µè¯ï¼Œå°å«ä¸ºæ‚¨æœåŠ¡ã€‚</code>å…±æœ‰5ä¸ªå¤šéŸ³å­—ï¼Œç”±äºæ¨¡å‹æ˜¯æŒ‰ç…§æ¯ä¸ªå­—å»è®­ç»ƒçš„ï¼Œåˆ™ä¸€å¥è¯éœ€è¦åå¤æ¨æ–­5æ¬¡ï¼Œè¿™é‡Œæ¯”è¾ƒæµªè´¹æ—¶é—´å’Œèµ„æºã€‚</li>
</ul>
<h2 id="ä»£ç è¯¦è§£"><a class="markdownIt-Anchor" href="#ä»£ç è¯¦è§£"></a> ä»£ç è¯¦è§£</h2>
<p>ä»ä¸Šé¢çš„æ¡†æ¶å›¾å¯ä»¥çœ‹å‡ºï¼Œç›¸å¯¹æ¥è¯´å¾ˆç®€å•äº†ã€‚</p>
<h3 id="æ•°æ®å¤„ç†"><a class="markdownIt-Anchor" href="#æ•°æ®å¤„ç†"></a> æ•°æ®å¤„ç†</h3>
<p>åˆ©ç”¨ Pytorch æ„å»º datasetï¼Œé€šè¿‡å¤„ç†ç”Ÿæˆå¦‚ä¸‹æ•°æ®</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">outputs &#x3D; &#123;</span><br><span class="line">    &#39;input_ids&#39;: input_ids,</span><br><span class="line">    &#39;token_type_ids&#39;: token_type_ids,</span><br><span class="line">    &#39;attention_mask&#39;: attention_mask,</span><br><span class="line">    &#39;phoneme_mask&#39;: phoneme_mask, </span><br><span class="line">    &#39;char_id&#39;: char_id,                 </span><br><span class="line">    &#39;position_id&#39;: position_id,         </span><br><span class="line">    &#39;pos_id&#39; &#x3D; pos_id,                  </span><br><span class="line">    &#39;label_id&#39; &#x3D; label_id               </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">1. input_idsï¼š åŸå§‹æ–‡æœ¬å¯¹åº”çš„id, è¿™ä¸ªidæ˜¯æ ¹æ® bert ä¸­ tokenizer å¯¹åº”çš„</span><br><span class="line">2. token_type_idsï¼šå…¨ä¸º 0 çš„å‘é‡ï¼Œè¿™ä¸ªæ˜¯ä¸º bert æä¾›çš„ï¼Œå…¨ä¸º0è¡¨ç¤ºéƒ½æ˜¯ä¸ŠåŠå¥</span><br><span class="line">3. attention_maskï¼šå…¨ä¸º 1 çš„å‘é‡ï¼Œè¿™ä¸ªæ˜¯ä¸º bert æä¾›çš„ï¼Œå…¨ä¸º1è¡¨ç¤ºä¸maskï¼Œæ‰€æœ‰è¯å‡å‚ä¸è®¡ç®—</span><br><span class="line">4. phoneme_maskï¼šå¤šéŸ³å­— hard mask, å‘é‡é•¿åº¦ä¸ºæ‰€æœ‰å¤šéŸ³å­—å¯èƒ½å‘éŸ³çš„é•¿åº¦ï¼ˆCPPæ•°æ®é›†ä¸º650ï¼‰ï¼Œå¤šéŸ³å­—å¯¹åº”å­—ç¬¦å¯èƒ½å‘éŸ³çš„ä¸º1ï¼Œå…¶ä½™ä½ç½®ä¸º0</span><br><span class="line">5. char_idsï¼šå¤šéŸ³å­— idï¼Œè¿™ä¸ªæ˜¯å¤šéŸ³å­—å¤„äºå¤šéŸ³å­—åºåˆ—çš„ä½ç½®idï¼Œç”¨äºåç»­Embedding</span><br><span class="line">6. position_idsï¼šå¤šéŸ³å­—æ‰€åœ¨å¥å­ä¸­çš„ä½ç½®idï¼Œç”¨äºæˆªå–Bertè¾“å‡ºçš„ç»“æœ</span><br><span class="line">7. pos_idsï¼š# è¡¨ç¤ºå¤šéŸ³å­—å¯¹åº”çš„ POSï¼Œç”¨äºåç»­POSé¢„æµ‹ä¸åˆ©ç”¨POSå¸®åŠ©å¤šéŸ³å­—é¢„æµ‹</span><br><span class="line">8. label_idsï¼šå¤šéŸ³å­—çš„ GroundTruth</span><br></pre></td></tr></table></figure>
<p>æ•°æ®å¤„ç†è¿‡ç¨‹æœ‰å¦‚ä¸‹éœ€è¦æ³¨æ„çš„ç‚¹ï¼š</p>
<ul>
<li>å¯¹åŸå§‹ sentence æŒ‰ç…§ window=32 è¿›è¡Œäº†åˆ‡åˆ†ï¼Œå³ä»¥å¤šéŸ³å­—ä¸ºä¸­å¿ƒï¼Œå·¦å³ä¸¤è¾¹æ–‡æœ¬çš„é•¿åº¦æœ€å¤§ä¸º16ï¼Œè¶…è¿‡çš„åˆ™å‰ªåˆ‡ã€‚</li>
<li>å¤šéŸ³å­—POSæ˜¯åˆ©ç”¨ckiptagger package ç”Ÿæˆçš„ï¼Œåœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨äº† Teacher Forcingçš„åšæ³•ï¼Œå³åˆ©ç”¨çœŸå®çš„POSå»å¹²é¢„åç»­å¤šéŸ³å­—é¢„æµ‹ã€‚</li>
</ul>
<h3 id="æ ¸å¿ƒæ¨¡å‹"><a class="markdownIt-Anchor" href="#æ ¸å¿ƒæ¨¡å‹"></a> æ ¸å¿ƒæ¨¡å‹</h3>
<p>æ ¸å¿ƒæ˜¯ BERT å’Œ çº¿æ€§å±‚ï¼Œæ ¸å¿ƒæ¨¡å‹æ³¨æ„çš„ç‚¹å¦‚ä¸‹ï¼š</p>
<ul>
<li>BERTæ²¡æœ‰å›ºå®šå‚æ•°ï¼Œä¸€åŒè¿›è¡Œè®­ç»ƒï¼›</li>
<li>conditional weight layerï¼šä¸‰ä¸ªnn.Embeddingï¼Œä¸€ä¸ªæ˜¯å¤šéŸ³å­—idï¼Œä¸€ä¸ªæ˜¯å¤šéŸ³å­—ä¸POSç»“åˆçš„idï¼Œä¸€ä¸ªæ˜¯biasï¼Œç„¶åé€šè¿‡sigmoidè·å¾—æ¯ä¸ªä¸ªå¯èƒ½label_idsçš„æ¦‚ç‡ï¼Œè¿™ä¸ªæ˜¯softï¼Œç„¶åä¹˜ä»¥æœ€åçš„phoneme_maskï¼ˆè¿™ä¸ªæ˜¯hard maskï¼‰,å¾—åˆ°æœ€åçš„weightã€‚</li>
<li>POSç”¨äºå¤šéŸ³å­—é¢„æµ‹ä¸­å¼•å…¥äº†Teacher Forcing</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"># è¿™é‡Œæ˜¯é’ˆå¯¹CPPå‚æ•°ç®€åŒ–çš„æ¨¡å‹</span><br><span class="line"></span><br><span class="line">class G2PW(BertPreTrainedModel):</span><br><span class="line">    def __init__(self, model_source, labels, chars, pos_tags,</span><br><span class="line">                 use_conditional&#x3D;False, param_conditional&#x3D;None,</span><br><span class="line">                 use_focal&#x3D;False, param_focal&#x3D;None,</span><br><span class="line">                 use_pos&#x3D;False, param_pos&#x3D;None):</span><br><span class="line">        super().__init__(model_source)       # bert-base-chinese</span><br><span class="line"></span><br><span class="line">        self.num_labels &#x3D; len(labels)        # 650 ä¸ªå¤šéŸ³å­— phoneme</span><br><span class="line">        self.num_chars &#x3D; len(chars)          # 623 ä¸ªå¤šéŸ³å­—ç¬¦</span><br><span class="line">        self.num_pos_tags &#x3D; len(pos_tags)    # 11 ä¸ªè¯æ€§æ ‡ç­¾</span><br><span class="line"></span><br><span class="line">        self.bert &#x3D; BertModel(self.config)</span><br><span class="line"></span><br><span class="line">        self.classifier &#x3D; nn.Linear(self.config.hidden_size, self.num_labels)   # 768 ---&gt; 650</span><br><span class="line"></span><br><span class="line">        self.use_conditional &#x3D; use_conditional  # True</span><br><span class="line">        self.param_conditional &#x3D; param_conditional</span><br><span class="line">        if self.use_conditional:</span><br><span class="line">            conditional_affect_location &#x3D; self.param_conditional[&#39;affect_location&#39;]</span><br><span class="line">            target_size &#x3D; self.config.hidden_size if conditional_affect_location &#x3D;&#x3D; &#39;emb&#39; else self.num_labels</span><br><span class="line"></span><br><span class="line">            if self.param_conditional[&#39;bias&#39;]:  # True</span><br><span class="line">                self.descriptor_bias &#x3D; nn.Embedding(1, target_size)</span><br><span class="line">            if self.param_conditional[&#39;char-linear&#39;]:  # True</span><br><span class="line">                self.char_descriptor &#x3D; nn.Embedding(self.num_chars, target_size)</span><br><span class="line">            if self.param_conditional[&#39;char+pos-second&#39;]:  # True</span><br><span class="line">                self.second_order_descriptor &#x3D; nn.Embedding(self.num_chars * self.num_pos_tags, target_size)</span><br><span class="line">        </span><br><span class="line">        self.use_pos &#x3D; use_pos  # True</span><br><span class="line">        self.param_pos &#x3D; param_pos  #</span><br><span class="line">        # &#39;param_pos &#39;: &#123;</span><br><span class="line">        #     &#39;weight&#39;: 0.1,</span><br><span class="line">        #     &#39;pos_joint_training&#39;: True,</span><br><span class="line">        #     &#39;train_pos_path&#39;: &#39;train.pos&#39;,</span><br><span class="line">        #     &#39;valid_pos_path&#39;: &#39;dev.pos&#39;,</span><br><span class="line">        #     &#39;test_pos_path&#39;: &#39;test.pos&#39;</span><br><span class="line">        # &#125;</span><br><span class="line">        if self.use_pos and self.param_pos[&#39;pos_joint_training&#39;]:</span><br><span class="line">            self.pos_classifier &#x3D; nn.Linear(self.config.hidden_size, self.num_pos_tags)</span><br><span class="line">            # pos åˆ†ç±»</span><br><span class="line">    </span><br><span class="line">    def _weighted_softmax(self, logits, weights, eps):</span><br><span class="line">        max_logits, _ &#x3D; torch.max(logits, dim&#x3D;-1, keepdim&#x3D;True)</span><br><span class="line">        weighted_exp_logits &#x3D; torch.exp(logits - max_logits) * weights</span><br><span class="line">        # è¿™é‡Œçº¿æ€§å±‚ä¹‹åæ‰‹å†™äº† softmax å‡½æ•°ï¼Œä¸ºçš„å°±æ˜¯ * weights</span><br><span class="line">        norm &#x3D; torch.sum(weighted_exp_logits, dim&#x3D;-1, keepdim&#x3D;True)</span><br><span class="line">        probs &#x3D; weighted_exp_logits &#x2F; norm</span><br><span class="line">        probs &#x3D; torch.clamp(probs, min&#x3D;eps, max&#x3D;1-eps)</span><br><span class="line">        return probs</span><br><span class="line">    </span><br><span class="line">    def forward(self, input_ids, token_type_ids, attention_mask, phoneme_mask, char_ids, position_ids, pos_ids&#x3D;None, label_ids&#x3D;None, eps&#x3D;1e-6):</span><br><span class="line">        transformers_major_ver &#x3D; int(transformers.__version__.split(&#39;.&#39;)[0])</span><br><span class="line">        # 4.6.1</span><br><span class="line">        if transformers_major_ver &gt;&#x3D; 4:</span><br><span class="line">            sequence_output, pooled_output &#x3D; self.bert(</span><br><span class="line">                input_ids,</span><br><span class="line">                token_type_ids&#x3D;token_type_ids,</span><br><span class="line">                attention_mask&#x3D;attention_mask,</span><br><span class="line">                return_dict&#x3D;False</span><br><span class="line">            )</span><br><span class="line">        else:</span><br><span class="line">            sequence_output, pooled_output &#x3D; self.bert(</span><br><span class="line">                input_ids,</span><br><span class="line">                token_type_ids&#x3D;token_type_ids,</span><br><span class="line">                attention_mask&#x3D;attention_mask</span><br><span class="line">            )</span><br><span class="line">        # sequence_output  [256, 34, 768]</span><br><span class="line">        batch_size &#x3D; input_ids.size(0)</span><br><span class="line">        orig_selected_hidden &#x3D; sequence_output[torch.arange(batch_size), position_ids]</span><br><span class="line">        selected_hidden &#x3D; orig_selected_hidden  # [256, 768]</span><br><span class="line">        if self.use_conditional:</span><br><span class="line">            if (self.param_conditional[&#39;char+pos-second&#39;]</span><br><span class="line">                    or self.param_conditional[&#39;char+pos-second_lowrank&#39;]</span><br><span class="line">                    or self.param_conditional[&#39;char+pos-second_fm&#39;]</span><br><span class="line">                    or self.param_conditional[&#39;pos-linear&#39;]</span><br><span class="line">                    or self.param_conditional[&#39;fix_mode&#39;] &#x3D;&#x3D; &#39;count_distr:char+pos&#39;):</span><br><span class="line">                pred_pos_ids &#x3D; pos_ids if self.training or not self.param_pos[&#39;pos_joint_training&#39;] \</span><br><span class="line">                    else self.pos_classifier(orig_selected_hidden).argmax(dim&#x3D;-1)  # teacher mode while training</span><br><span class="line">            # pred_pos_ids  [256]</span><br><span class="line">            affect_terms &#x3D; []</span><br><span class="line">            if self.param_conditional[&#39;bias&#39;]:  # True</span><br><span class="line">                bias_tensor &#x3D; self.descriptor_bias(torch.zeros_like(char_ids))</span><br><span class="line">                # print(char_ids.shape)      [256]</span><br><span class="line">                # print(bias_tensor.shape)   [256, 650]</span><br><span class="line">                affect_terms.append(bias_tensor)</span><br><span class="line">            if self.param_conditional[&#39;char-linear&#39;]:  # True</span><br><span class="line">                affect_terms.append(self.char_descriptor(char_ids))</span><br><span class="line">            if self.param_conditional[&#39;char+pos-second&#39;]:  # true</span><br><span class="line">                char_pos_ids &#x3D; self._get_char_pos_ids(char_ids, pred_pos_ids)</span><br><span class="line">                affect_terms.append(self.second_order_descriptor(char_pos_ids))</span><br><span class="line">            affect_hidden &#x3D; sum(affect_terms)</span><br><span class="line">            # softmax</span><br><span class="line">            phoneme_mask &#x3D; phoneme_mask * torch.sigmoid(affect_hidden)</span><br><span class="line"></span><br><span class="line">        logits &#x3D; self.classifier(selected_hidden)</span><br><span class="line">        probs &#x3D; self._weighted_softmax(logits, phoneme_mask, eps)</span><br><span class="line">        if label_ids is not None:</span><br><span class="line">            if self.use_focal:</span><br><span class="line">                loss_layer &#x3D; ModifiedFocalLoss(alpha&#x3D;self.param_focal[&#39;alpha&#39;], gamma&#x3D;self.param_focal[&#39;gamma&#39;])</span><br><span class="line">                loss &#x3D; loss_layer(probs, label_ids)</span><br><span class="line">            else:</span><br><span class="line">                loss_layer &#x3D; nn.NLLLoss()</span><br><span class="line">                log_probs &#x3D; torch.log(probs)</span><br><span class="line">                loss &#x3D; loss_layer(log_probs, label_ids)</span><br><span class="line">                # æœ€åå¤šéŸ³å­—çš„æŸå¤±</span><br><span class="line"></span><br><span class="line">            pos_logits &#x3D; None</span><br><span class="line">            if self.use_pos and pos_ids is not None and self.param_pos[&#39;pos_joint_training&#39;]:</span><br><span class="line">                pos_logits &#x3D; self.pos_classifier(orig_selected_hidden)</span><br><span class="line">                loss_fct &#x3D; nn.CrossEntropyLoss()  # nn.logSoftmax()å’Œnn.NLLLoss()çš„ç»“åˆ</span><br><span class="line">                pos_loss &#x3D; loss_fct(pos_logits, pos_ids)</span><br><span class="line">                scaling &#x3D; self._get_pos_loss_scaling_when_using_focal(probs, label_ids) if self.use_focal else 1.</span><br><span class="line">                loss +&#x3D; self.param_pos[&#39;weight&#39;] * scaling * pos_loss</span><br><span class="line"></span><br><span class="line">            return probs, loss, pos_logits</span><br><span class="line">        else:</span><br><span class="line">            return probs                                </span><br></pre></td></tr></table></figure>
<h3 id="æ¨æ–­ä»£ç "><a class="markdownIt-Anchor" href="#æ¨æ–­ä»£ç "></a> æ¨æ–­ä»£ç </h3>
<ul>
<li>ç®€æ˜“ç‰ˆæ¨æ–­</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from poly import G2PWConverter</span><br><span class="line">conv &#x3D; G2PWConverter(model_dir&#x3D;&quot;saved_models&#x2F;CPP_BERT_M_DescWS-Sec-cLin-B_POSw01&#x2F;&quot;,</span><br><span class="line">                     style&#x3D;&#39;pinyin&#39;, enable_non_tradional_chinese&#x3D;False, use_cuda&#x3D;True)</span><br><span class="line">conv(&#39;ä½ å¥½&#39;)</span><br></pre></td></tr></table></figure>
<h2 id="æµ‹è¯•ç»“æœ"><a class="markdownIt-Anchor" href="#æµ‹è¯•ç»“æœ"></a> æµ‹è¯•ç»“æœ</h2>
<ul>
<li>æ¨æ–­ä»£ç ä¸­bopomofoå¤šéŸ³å­—å­˜åœ¨é—®é¢˜ï¼Œè¿™æ˜¯å­—å…¸è®¾ç½®çš„é—®é¢˜ã€‚</li>
<li>æ¨æ–­è¿‡ç¨‹è¿è¡Œè¾ƒæ»¡ï¼Œæ¯å¥å¤§æ¦‚éœ€è¦0.2s,ç›´æ¥ç”¨åˆ°TTSè‚¯å®šä¸è¡Œï¼Œéœ€è¦é‡å†™G2PWConverteræä¾›çš„api</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">é¢„æµ‹å‡†ç¡®çš„æ¡ˆä¾‹ï¼š</span><br><span class="line">&#123;</span><br><span class="line">å«å¥å§”æµè°ƒ&lt;diao4, tiao2&gt;ç”µè¯ï¼Œä¸º&lt;wei2, wei4&gt;æ‚¨æœåŠ¡</span><br><span class="line">[[&#39;wei4&#39;, &#39;jian4&#39;, &#39;wei3&#39;, &#39;liu2&#39;, &#39;diao4&#39;, &#39;dian4&#39;, &#39;hua4&#39;, None, &#39;wei4&#39;, &#39;nin2&#39;, &#39;fu2&#39;, &#39;wu4&#39;]]</span><br><span class="line">&#125;</span><br><span class="line">é¢„æµ‹å¤±è´¥çš„æ¡ˆä¾‹ï¼š(è¿™é‡Œæ˜¯bopomofoå­—å…¸é—®é¢˜ï¼Œåç»­éœ€è¦æ”¹è¿›)</span><br><span class="line">&#123;</span><br><span class="line">é•¿&lt;chang2, zhang3&gt;æœŸ</span><br><span class="line">[[&#39;zhang3&#39;, &#39;qi1&#39;]]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="æ”¹è¿›"><a class="markdownIt-Anchor" href="#æ”¹è¿›"></a> æ”¹è¿›</h2>
<ul>
<li>å®Œæ•´ç‰ˆæœ¬æ¨æ–­</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line">class G2PWConverter:</span><br><span class="line">    def __init__(self, model_dir&#x3D;&#39;G2PWModel&#x2F;&#39;, style&#x3D;&#39;bopomofo&#39;, model_source&#x3D;None, use_cuda&#x3D;False, num_workers&#x3D;None, batch_size&#x3D;None,</span><br><span class="line">                 turnoff_tqdm&#x3D;True, enable_non_tradional_chinese&#x3D;False):</span><br><span class="line">        if not os.path.exists(os.path.join(model_dir, &#39;best_accuracy.pth&#39;)):</span><br><span class="line">            download_model(model_dir)</span><br><span class="line">        self.model_dir &#x3D; model_dir</span><br><span class="line">        self.config &#x3D; load_config(os.path.join(model_dir, &#39;config.py&#39;), use_default&#x3D;True)</span><br><span class="line"></span><br><span class="line">        self.num_workers &#x3D; num_workers if num_workers else self.config.num_workers</span><br><span class="line">        self.batch_size &#x3D; batch_size if batch_size else self.config.batch_size</span><br><span class="line">        self.model_source &#x3D; model_source if model_source else self.config.model_source</span><br><span class="line">        self.turnoff_tqdm &#x3D; turnoff_tqdm</span><br><span class="line">        self.enable_opencc &#x3D; enable_non_tradional_chinese</span><br><span class="line"></span><br><span class="line">        self.device &#x3D; torch.device(&#39;cuda&#39; if use_cuda else &#39;cpu&#39;)</span><br><span class="line"></span><br><span class="line">        self.tokenizer &#x3D; BertTokenizer.from_pretrained(self.config.model_source)</span><br><span class="line"></span><br><span class="line">        polyphonic_chars_path &#x3D; os.path.join(model_dir, &#39;POLYPHONIC_CHARS.txt&#39;)</span><br><span class="line">        polyphonic_chars_path_s &#x3D; os.path.join(model_dir, &#39;POLYPHONIC_CHARS_S.txt&#39;)</span><br><span class="line">        monophonic_chars_path &#x3D; os.path.join(model_dir, &#39;MONOPHONIC_CHARS.txt&#39;)</span><br><span class="line">        self.polyphonic_chars &#x3D; [line.split(&#39;\t&#39;) for line in open(polyphonic_chars_path).read().strip().split(&#39;\n&#39;)]</span><br><span class="line">        self.polyphonic_chars_s &#x3D; [line.split(&#39;\t&#39;) for line in open(polyphonic_chars_path_s).read().strip().split(&#39;\n&#39;)]</span><br><span class="line">        # polyphonic_chars 8022</span><br><span class="line">        self.monophonic_chars &#x3D; [line.split(&#39;\t&#39;) for line in open(monophonic_chars_path).read().strip().split(&#39;\n&#39;)]</span><br><span class="line">        # monophonic_chars 9476</span><br><span class="line">        self.labels, self.char2phonemes &#x3D; get_char_phoneme_labels(self.polyphonic_chars) if self.config.use_char_phoneme else get_phoneme_labels(self.polyphonic_chars)</span><br><span class="line">        self.labels_s, self.char2phonemes_s &#x3D; get_char_phoneme_labels(</span><br><span class="line">            self.polyphonic_chars_s) if self.config.use_char_phoneme else get_phoneme_labels(self.polyphonic_chars_s)</span><br><span class="line">        # self.labels 1305, å…± 1305ä¸ª bopomofo å‘éŸ³</span><br><span class="line">        # char2phonemesï¼Œå…± 3582 ä¸ªå¤šå› å­—ç¬¦</span><br><span class="line">        self.chars &#x3D; sorted(list(self.char2phonemes.keys()))</span><br><span class="line">        self.pos_tags &#x3D; TextDataset.POS_TAGS</span><br><span class="line"></span><br><span class="line">        self.model &#x3D; G2PW.from_pretrained(</span><br><span class="line">            self.model_source,</span><br><span class="line">            labels&#x3D;self.labels,</span><br><span class="line">            chars&#x3D;self.chars,</span><br><span class="line">            pos_tags&#x3D;self.pos_tags,</span><br><span class="line">            use_conditional&#x3D;self.config.use_conditional,</span><br><span class="line">            param_conditional&#x3D;self.config.param_conditional,</span><br><span class="line">            use_focal&#x3D;self.config.use_focal,</span><br><span class="line">            param_focal&#x3D;self.config.param_focal,</span><br><span class="line">            use_pos&#x3D;self.config.use_pos,</span><br><span class="line">            param_pos&#x3D;self.config.param_pos</span><br><span class="line">        )</span><br><span class="line">        checkpoint &#x3D; os.path.join(model_dir, &#39;best_accuracy.pth&#39;)</span><br><span class="line">        self.model.load_state_dict(torch.load(checkpoint, map_location&#x3D;self.device))</span><br><span class="line">        self.model.to(self.device)</span><br><span class="line"></span><br><span class="line">        with open(os.path.join(os.path.dirname(os.path.abspath(__file__)),</span><br><span class="line">                               &#39;bopomofo_to_pinyin_wo_tune_dict.json&#39;), &#39;r&#39;) as fr:</span><br><span class="line">            self.bopomofo_convert_dict &#x3D; json.load(fr)</span><br><span class="line">            # è¿™é‡Œæ‰æœ‰ 424 ä¸ªï¼Œè¿™ä¸ª wo tune åˆ°åº•æ˜¯å•¥ï¼Œè¿™é‡Œåº”è¯¥å°±æ˜¯ bopomofo å¯¹åº”çš„ pinyin, å‡ºé”™ä¸åº”è¯¥æ˜¯è¿™é‡Œ</span><br><span class="line">        self.style_convert_func &#x3D; &#123;</span><br><span class="line">            &#39;bopomofo&#39;: lambda x: x,</span><br><span class="line">            &#39;pinyin&#39;: self._convert_bopomofo_to_pinyin,</span><br><span class="line">        &#125;[style]</span><br><span class="line"></span><br><span class="line">        with open(os.path.join(os.path.dirname(os.path.abspath(__file__)),</span><br><span class="line">                               &#39;char_bopomofo_dict.json&#39;), &#39;r&#39;) as fr:</span><br><span class="line">            self.char_bopomofo_dict &#x3D; json.load(fr)</span><br><span class="line">            # char_bopomofo_dict: æ±‰å­—åˆ°bopomofoçš„å­—å…¸ï¼Œ41497</span><br><span class="line"></span><br><span class="line">        if self.enable_opencc:</span><br><span class="line">            self.cc &#x3D; OpenCC(&#39;s2tw&#39;)  # å°†ä¸­æ–‡ç®€ä½“è½¬æ¢ä¸ºç¹ä½“ï¼Œä»¥å°æ¹¾æ ‡å‡†</span><br><span class="line"></span><br><span class="line">    def _convert_bopomofo_to_pinyin(self, bopomofo):</span><br><span class="line">        tone &#x3D; bopomofo[-1]</span><br><span class="line">        assert tone in &#39;12345&#39;</span><br><span class="line">        component &#x3D; self.bopomofo_convert_dict.get(bopomofo[:-1])</span><br><span class="line">        if component:</span><br><span class="line">            return component + tone</span><br><span class="line">        else:</span><br><span class="line">            print(f&#39;Warning: &quot;&#123;bopomofo&#125;&quot; cannot convert to pinyin&#39;)</span><br><span class="line">            return None</span><br><span class="line"></span><br><span class="line">    def __call__(self, sentences):</span><br><span class="line"></span><br><span class="line">        # s &#x3D; time.time()</span><br><span class="line">        if isinstance(sentences, str):</span><br><span class="line">            sentences &#x3D; [sentences]</span><br><span class="line">        # e &#x3D; time.time()</span><br><span class="line">        # print(&#39;ç¬¬ä¸€æ­¥æ—¶é—´: %4f&#39; % (e - s))</span><br><span class="line">        # s &#x3D; time.time()</span><br><span class="line">        if self.enable_opencc:</span><br><span class="line">            translated_sentences &#x3D; []</span><br><span class="line">            for sent in sentences:</span><br><span class="line">                translated_sent &#x3D; self.cc.convert(sent)</span><br><span class="line">                assert len(translated_sent) &#x3D;&#x3D; len(sent)</span><br><span class="line">                translated_sentences.append(translated_sent)</span><br><span class="line">            sentences &#x3D; translated_sentences</span><br><span class="line">        # e &#x3D; time.time()</span><br><span class="line">        # print(&#39;ç¬¬äºŒæ­¥æ—¶é—´: %4f&#39; % (e - s))</span><br><span class="line">        # s &#x3D; time.time()</span><br><span class="line">        texts, query_ids, sent_ids, partial_results &#x3D; self._prepare_data(sentences)</span><br><span class="line">        # e &#x3D; time.time()</span><br><span class="line">        # print(&#39;ç¬¬ä¸‰æ­¥æ—¶é—´: %4f&#39; % (e - s))</span><br><span class="line">        # s &#x3D; time.time()</span><br><span class="line">        dataset &#x3D; TextDataset(self.tokenizer, self.labels, self.char2phonemes_s, self.chars, texts, query_ids,</span><br><span class="line">                              use_mask&#x3D;self.config.use_mask, use_char_phoneme&#x3D;self.config.use_char_phoneme,</span><br><span class="line">                              window_size&#x3D;self.config.window_size, for_train&#x3D;False)</span><br><span class="line"></span><br><span class="line">        dataloader &#x3D; DataLoader(</span><br><span class="line">            dataset&#x3D;dataset,</span><br><span class="line">            batch_size&#x3D;self.batch_size,</span><br><span class="line">            collate_fn&#x3D;dataset.create_mini_batch,</span><br><span class="line">            num_workers&#x3D;self.num_workers</span><br><span class="line">        )</span><br><span class="line">        # e &#x3D; time.time()</span><br><span class="line">        # print(&#39;time data: %4f&#39; % (e-s))</span><br><span class="line">        s &#x3D; time.time()</span><br><span class="line">        preds, confidences &#x3D; predict(self.model, dataloader, self.device, self.labels, turnoff_tqdm&#x3D;self.turnoff_tqdm)</span><br><span class="line">        e &#x3D; time.time()</span><br><span class="line">        print(&#39;time predict: %4f&#39; % (e-s))</span><br><span class="line">        if self.config.use_char_phoneme:</span><br><span class="line">            preds &#x3D; [pred.split(&#39; &#39;)[1] for pred in preds]</span><br><span class="line"></span><br><span class="line">        # s &#x3D; time.time()</span><br><span class="line">        results &#x3D; partial_results</span><br><span class="line">        for sent_id, query_id, pred in zip(sent_ids, query_ids, preds):</span><br><span class="line">            if self.model_dir &#x3D;&#x3D; &#39;G2PWModel&#x2F;&#39;:</span><br><span class="line">                results[sent_id][query_id] &#x3D; self.style_convert_func(pred)</span><br><span class="line">            else:</span><br><span class="line">                results[sent_id][query_id] &#x3D; pred</span><br><span class="line">        # e &#x3D; time.time()</span><br><span class="line">        # print(&#39;time results: %4f&#39; % (e - s))</span><br><span class="line">        return results</span><br><span class="line"></span><br><span class="line">    def _prepare_data(self, sentences):</span><br><span class="line">        # polyphonic_chars &#x3D; set(self.chars)  # 3582 ä¸ªå¤šéŸ³å­— ï¼ˆè¿™ä¸ªå¤šéŸ³å­—æ˜¯ç¼ºå¤±çš„ï¼Œæ¯”å¦‚æ²¡æœ‰ â€œé•¿â€ï¼‰</span><br><span class="line">        polyphonic_chars &#x3D; set(sorted(list(self.char2phonemes_s.keys())))  # 3582 ä¸ªå¤šéŸ³å­— ï¼ˆè¿™ä¸ªå¤šéŸ³å­—æ˜¯ç¼ºå¤±çš„ï¼Œæ¯”å¦‚æ²¡æœ‰ â€œé•¿â€ï¼‰</span><br><span class="line">        # è¿™é‡Œæˆ‘æ–°å¢äº†ä¸€ä¸ªæœç´¢ å¤šéŸ³å­—å­—å…¸ï¼Œç”±äºç½‘ç»œä¸­ç”¨åˆ°äº† char_id Embedding, æ‰€ä»¥åŸå§‹çš„ä¸èƒ½ä¿®æ”¹ï¼Œ</span><br><span class="line">        # æˆ‘æƒ³åœ¨è·å– char_id ä¸­ åˆ©ç”¨éšæœºæ•°å»é¢„æµ‹</span><br><span class="line">        monophonic_chars_dict &#x3D; &#123;</span><br><span class="line">            char: phoneme for char, phoneme in self.monophonic_chars</span><br><span class="line">        &#125;</span><br><span class="line">        texts, query_ids, sent_ids, partial_results &#x3D; [], [], [], []</span><br><span class="line">        for sent_id, sent in enumerate(sentences):</span><br><span class="line">            partial_result &#x3D; [None] * len(sent)</span><br><span class="line">            for i, char in enumerate(sent):</span><br><span class="line">                if char in polyphonic_chars:</span><br><span class="line">                    texts.append(sent)</span><br><span class="line">                    query_ids.append(i)</span><br><span class="line">                    sent_ids.append(sent_id)</span><br><span class="line">                elif char in monophonic_chars_dict:</span><br><span class="line">                    # å…ˆå» è‡ªå·±å®šä¹‰çš„ å•éŸ³å­—å­—å…¸è¿›è¡ŒåŒ¹é…ï¼Œè¿˜æ˜¯æ²¡æœ‰ â€œé•¿â€ å­—</span><br><span class="line">                    partial_result[i] &#x3D;  self.style_convert_func(monophonic_chars_dict[char])</span><br><span class="line">                elif char in self.char_bopomofo_dict:</span><br><span class="line">                    # å†å»æœ€å¤§çš„å­—å…¸åŒ¹é…ï¼ˆè¿™é‡Œå°±æ˜¯é—®é¢˜æ‰€åœ¨äº†ï¼Œå¦‚æœæ˜¯å¤šéŸ³å­—ï¼Œé»˜è®¤ä»…ä»…å–ç¬¬1ä¸ªå®šä¹‰çš„å‘éŸ³ï¼ï¼‰</span><br><span class="line">                    partial_result[i] &#x3D;  self.style_convert_func(self.char_bopomofo_dict[char][0])</span><br><span class="line">            partial_results.append(partial_result)</span><br><span class="line">        return texts, query_ids, sent_ids, partial_results</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>è¿™é‡Œä¸»è¦ä¿®æ”¹çš„ç‚¹æ˜¯ï¼š</p>
<ul>
<li>é‡æ–°åŠ è½½äº†å¤šéŸ³å­—å­—å…¸ï¼Œæ„å»ºäº†<code>POLYPHONIC_CHARS_S.txt</code>ç”¨äºæ£€ç´¢sentencesæ˜¯å¦å­˜åœ¨å¤šéŸ³å­—ï¼Œè¿™é‡Œæˆ‘ä»¬å°±å¯ä»¥æ–°å¢å¤šéŸ³å­—äº†ï¼Œå¤§å¤§å¢åŠ äº†å¯æ‰©å±•æ€§ã€‚</li>
<li>ç”±äºæ¨¡å‹ä¸­åº”ç”¨äº† char_id å¤šéŸ³å­—IDè¿›è¡Œäº† Embedding è¾…åŠ©è®­ç»ƒï¼Œè¿™é‡Œé€šè¿‡<code>POLYPHONIC_CHARS_S.txt</code>æ–°å¢çš„å¤šéŸ³å­—æ˜¯æ²¡æœ‰å¯¹åº”çš„ char_id çš„ï¼Œæˆ‘é‡å†™äº† datasetéƒ¨åˆ†ï¼Œå°†æ²¡æœ‰å¯¹åº”çš„å¤šéŸ³å­— char_id å¯¹åº”ä¸º0ã€‚è¿™ä¸ªæ²¡æœ‰å¤ªå¤šé“ç†ï¼Œæˆ‘è§‰å¾—åœ¨æ¨¡å‹éƒ¨åˆ† BERT çš„é‡è¦ç¨‹åº¦è¦è¿œè¿œå¤§äº char_id_embedding, äº‹å®è¯æ˜ç¡®å®æ˜¯çš„ã€‚</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># datasetéƒ¨åˆ†ä¿®æ”¹</span><br><span class="line">char_id &#x3D; self.chars.index(query_char) if query_char in self.chars else 0</span><br><span class="line">phoneme_mask &#x3D; [1 if i in self.char2phonemes[query_char] else 0 for i in range(len(self.labels))] \</span><br><span class="line">    if self.use_mask else [1] * len(self.labels)</span><br><span class="line"># æ³¨æ„è¿™é‡Œ char2phonemes æ˜¯æ ¹æ®æ–°çš„å¤šéŸ³å­—å­—å…¸ç”Ÿæˆçš„ã€‚</span><br></pre></td></tr></table></figure>
<p>è¿˜å¯èƒ½å‡ºç°çš„é—®é¢˜æ˜¯ï¼š</p>
<ul>
<li>æ–°å¢äº†å¤šéŸ³å­—ï¼Œä½†æ˜¯å¤šéŸ³å­—çš„å‘éŸ³ä¸åœ¨ phonemes ä¸­ã€‚è¿™ç§å°±å¾ˆéš¾è¯¥äº†ï¼Œå› ä¸ºæ¨æ–­çš„ labels_num å·²ç»ç”±æ¨¡å‹å›ºå®šäº†ï¼Œéœ€è¦é‡æ–°ä¿®æ”¹æ¨¡å‹æ¡†æ¶ï¼Œå†è®­ç»ƒã€‚</li>
</ul>
<h3 id="å¿«é€Ÿæ¨ç†çš„æ€è€ƒ"><a class="markdownIt-Anchor" href="#å¿«é€Ÿæ¨ç†çš„æ€è€ƒ"></a> å¿«é€Ÿæ¨ç†çš„æ€è€ƒ</h3>
<ul>
<li>å°†ä¸€å¥ä¸­æ‰€æœ‰å¤šéŸ³å­—éƒ½æ ‡è¯†å‡ºæ¥ï¼Œä¸€å¥è¯ä»…ä»…æ¨æ–­ä¸€æ¬¡ï¼›</li>
<li>å°†éŸµå¾‹é¢„æµ‹æ¨¡å—è¿›è¡Œæ‹¼æ¥ï¼Œå‡å°‘ä¸€ä¸ªæ¨¡å‹ã€‚å¯ä»¥å‚è€ƒçš„è®ºæ–‡<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2012.15404">Unified Mandarin TTS Front-end Based on Distilled BERT Model</a></li>
<li>å°†åŸºç¡€æ¨¡å‹ <code>bert-base-chinese</code> æ¢æˆæ›´å°æ›´å¿«çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œæˆ–è€…è¿›è¡Œè’¸é¦ã€‚</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/TTS-Front-end/" rel="tag"># TTS Front-end</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/08/03/VITS/" rel="prev" title="VITS">
      <i class="fa fa-chevron-left"></i> VITS
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/08/15/Text-to-Face/" rel="next" title="æ–‡æœ¬è¯­éŸ³é©±åŠ¨æ•°å­—äººè¡¨æƒ…å£å‹ç«èµ›">
      æ–‡æœ¬è¯­éŸ³é©±åŠ¨æ•°å­—äººè¡¨æƒ…å£å‹ç«èµ› <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-number">1.</span> <span class="nav-text"> æ‘˜è¦</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E6%A1%86%E6%9E%B6"><span class="nav-number">1.1.</span> <span class="nav-text"> ä¸»è¦æ¡†æ¶</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="nav-number">1.2.</span> <span class="nav-text"> ä»£ç è¯¦è§£</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">1.2.1.</span> <span class="nav-text"> æ•°æ®å¤„ç†</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.2.</span> <span class="nav-text"> æ ¸å¿ƒæ¨¡å‹</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8E%A8%E6%96%AD%E4%BB%A3%E7%A0%81"><span class="nav-number">1.2.3.</span> <span class="nav-text"> æ¨æ–­ä»£ç </span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C"><span class="nav-number">1.3.</span> <span class="nav-text"> æµ‹è¯•ç»“æœ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B"><span class="nav-number">1.4.</span> <span class="nav-text"> æ”¹è¿›</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%AB%E9%80%9F%E6%8E%A8%E7%90%86%E7%9A%84%E6%80%9D%E8%80%83"><span class="nav-number">1.4.1.</span> <span class="nav-text"> å¿«é€Ÿæ¨ç†çš„æ€è€ƒ</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Xin Yuan"
      src="/images/me.jpg">
  <p class="site-author-name" itemprop="name">Xin Yuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">36</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yuan1615" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;yuan1615" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yuan1615@163.com" title="E-Mail â†’ mailto:yuan1615@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Xin Yuan</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
